# Streamlit app: Classifica√ß√£o Bin√°ria de Textos com LIME e SHAP
# Projeto para disciplina "T√≥picos Especiais em Programa√ß√£o"
# Dataset: SMS Spam Collection
# Single-file app with "pages" simulated via sidebar for 5 integrantes
# Requisitos (install):
# pip install streamlit scikit-learn pandas matplotlib seaborn lime shap joblib

import os
import io
import urllib.request
import zipfile
from pathlib import Path

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import joblib

# Interpretable libraries
from lime.lime_text import LimeTextExplainer
import shap

# ----------------------- Utilities -----------------------
DATA_URL = "https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
DATA_DIR = Path("data")
DATA_ZIP = DATA_DIR / "smsspamcollection.zip"
DATA_TXT = DATA_DIR / "SMSSpamCollection"
MODEL_DIR = Path("models")
MODEL_DIR.mkdir(exist_ok=True)


def download_and_extract_dataset():
    DATA_DIR.mkdir(exist_ok=True)
    if DATA_TXT.exists():
        return
    st.info("Baixando dataset SMS Spam Collection...")
    urllib.request.urlretrieve(DATA_URL, DATA_ZIP)
    with zipfile.ZipFile(DATA_ZIP, "r") as z:
        z.extractall(DATA_DIR)
    st.success("Dataset baixado e extra√≠do.")


def load_dataset():
    if not DATA_TXT.exists():
        download_and_extract_dataset()
    df = pd.read_csv(DATA_TXT, sep="\t", header=None, names=["label", "text"])
    return df


def preprocess_text(s: pd.Series, remove_stopwords=False):
    # m√≠nimo: lowercase and remove special characters
    import re
    s = s.str.lower()
    s = s.str.replace(r"[^a-z0-9\s]", " ", regex=True)
    s = s.str.replace(r"\s+", " ", regex=True).str.strip()
    # stopwords optional (simple english stopwords)
    if remove_stopwords:
        from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS
        s = s.apply(lambda t: " ".join([w for w in t.split() if w not in ENGLISH_STOP_WORDS]))
    return s


def train_vectorizers_and_models(X_train_text, y_train, use_tfidf=True, max_features=5000):
    if use_tfidf:
        vec = TfidfVectorizer(max_features=max_features)
    else:
        vec = CountVectorizer(max_features=max_features)
    X_train = vec.fit_transform(X_train_text)
    # Use Logistic Regression (linear) as default
    clf = LogisticRegression(max_iter=200)
    clf.fit(X_train, y_train)
    return vec, clf


def evaluate_model(vec, clf, X_text, y_true):
    X = vec.transform(X_text)
    y_pred = clf.predict(X)
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    return {"accuracy": acc, "precision": prec, "recall": rec, "f1": f1}, y_pred

# ----------------------- Streamlit App -----------------------
st.set_page_config(page_title="Classifica√ß√£o Bin√°ria com LIME e SHAP", layout="wide")
st.title("Classifica√ß√£o Bin√°ria de Textos com LIME e SHAP")


# Sidebar "pages" for 5 integrantes
page = st.sidebar.selectbox("Selecionar p√°gina", (
    "Vis√£o Geral (s√≠ntese)",
    "1 - Pipeline textual e compara√ß√£o com tabular",
    "2 - Implementa√ß√£o dos modelos e m√©tricas",
    "3 - Explica√ß√µes com LIME",
    "4 - Explica√ß√µes com SHAP",
    "5 - S√≠ntese e An√°lise Cr√≠tica do Projeto"
))

with st.sidebar:
  
    st.subheader("Alunos:")
    st.markdown(""" \
    - Emanoel Sousa
    - Jos√© Macedo
    - Leonardo Vitorio
    - Marcos Ara√∫jo
    - Wadson Tardelle
    """
    )

# Load data once
with st.spinner("Carregando dataset..."):
    df = load_dataset()

# Encode labels: ham=0, spam=1
le = LabelEncoder()
df['label_enc'] = le.fit_transform(df['label'])


if "results_compare" not in st.session_state:
    st.session_state.results_compare = []


# Show quick dataset preview
if page == "Vis√£o Geral (s√≠ntese)":
    st.header("Resumo do projeto e estrutura do pipeline")
    st.markdown("""
    **Objetivo:** Construir um pipeline completo de classifica√ß√£o bin√°ria de textos (SMS) e explicar as previs√µes usando LIME e SHAP.

    **Etapas do pipeline:**
    1. Carregamento e pr√©-processamento de textos (lowercase, remover caracteres especiais, stopwords opcional).
    2. Representa√ß√µes: Bag-of-Words (CountVectorizer) e TF-IDF (TfidfVectorizer).
    3. Modelos lineares: Regress√£o Log√≠stica (ou SVM Linear).
    4. Avalia√ß√£o: Accuracy, Precision, Recall, F1-score. Matriz de confus√£o e relat√≥rio.
    5. Interpretabilidade: LIME (local) e SHAP (global + local), an√°lises comparativas.
    """)
    st.subheader("Preview do dataset")
    st.dataframe(df.sample(10, random_state=42))
    st.write("Distribui√ß√£o das classes:")
    fig, ax = plt.subplots()
    sns.countplot(x='label', data=df, ax=ax)
    ax.set_title('Count per class')
    st.pyplot(fig)
    st.markdown("\n---\nDeseja rodar experimentos? V√° para a p√°gina 'Integrante 2' para treinar modelos, 'Integrante 3' para LIME e 'Integrante 4' para SHAP.")

# ----------------------- Integrante 1 -----------------------
if page == "1 - Pipeline textual e compara√ß√£o com tabular":
    st.header("1 ‚Äî Pipeline textual e compara√ß√£o com dados tabulares")
    
    st.markdown("**Exemplo pr√°tico:** mostraremos transforma√ß√£o m√≠nima do texto e contagens de palavras (BOW) e TF-IDF)")

    remove_stop = st.checkbox("Remover stopwords (pr√©-processamento)", value=False)
    s = preprocess_text(df['text'], remove_stopwords=remove_stop)
    st.subheader("Exemplo de pr√©-processamento")
    st.table(pd.DataFrame({'orig': df['text'].head(6), 'preprocessed': s.head(6)}))

    st.subheader("Representa√ß√µes ‚Äî Top tokens")
    max_feats = st.slider("max_features (vocab size)", 500, 10000, 2000)
    bow = CountVectorizer(max_features=max_feats)
    tfidf = TfidfVectorizer(max_features=max_feats)
    bow.fit(s)
    tfidf.fit(s)
    bow_top = pd.Series(bow.vocabulary_).sort_values()[:20]
    st.write("Vocabul√°rio (amostra) ‚Äî Bag-of-Words")
    st.write(list(list(bow.vocabulary_.keys())[:30]))
    st.write("TF-IDF (amostra)")
    st.write(list(list(tfidf.vocabulary_.keys())[:30]))

    st.markdown("\n**Compara√ß√£o conceitual com dados tabulares:**\n- Textos exigem vetoriza√ß√£o (BOW/TF-IDF) para virar features num√©ricas.\n    - Dados tabulares com colunas j√° num√©ricas/categ√≥ricas exigem imputa√ß√£o/normaliza√ß√£o e codifica√ß√£o.\n    - Interpreta√ß√£o: em textos, features s√£o tokens (palavras/ngrams) enquanto em tabular cada coluna j√° √© uma feature leg√≠vel.\n    ")

# ----------------------- Integrante 2 -----------------------


if page == "2 - Implementa√ß√£o dos modelos e m√©tricas":
    st.header("2 ‚Äî Implementa√ß√£o dos modelos (BOW/TF-IDF) e m√©tricas")

    st.markdown("Escolha representa√ß√£o e treine modelos lineares. O treino pode demorar alguns segundos.")
    rep = st.radio("Representa√ß√£o", ("TF-IDF", "BOW"))
    max_feats = st.number_input("max_features", min_value=500, max_value=20000, value=5000, step=500)
    test_size = st.slider("test_size (fra√ß√£o)", 0.1, 0.5, 0.2)
    random_state = 42

    # preprocess
    s = preprocess_text(df['text'], remove_stopwords=False)
    X_train, X_test, y_train, y_test = train_test_split(s, df['label_enc'], test_size=test_size, stratify=df['label_enc'], random_state=random_state)

    use_tfidf = (rep == "TF-IDF")
    if st.button("Treinar modelo linear (LogisticRegression) e avaliar"):
        with st.spinner("Treinando..."):
            vec, clf = train_vectorizers_and_models(X_train, y_train, use_tfidf=use_tfidf, max_features=max_feats)
            joblib.dump(vec, MODEL_DIR / f"vectorizer_{rep}.pkl")
            joblib.dump(clf, MODEL_DIR / f"clf_logreg_{rep}.pkl")
        st.success("Treinamento conclu√≠do e modelos salvos em ./models/")

        metrics, y_pred = evaluate_model(vec, clf, X_test, y_test)
        st.subheader("M√©tricas de avalia√ß√£o")
        st.json(metrics)

        st.subheader("Classification Report")
        st.text(classification_report(y_test, y_pred, target_names=le.classes_))

        st.subheader("Matriz de Confus√£o")
        cm = confusion_matrix(y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, ax=ax)
        ax.set_xlabel('Predicted')
        ax.set_ylabel('True')
        st.pyplot(fig)
    
        metrics, y_pred = evaluate_model(vec, clf, X_test, y_test)

        result = {
            "Representa√ß√£o": rep,
            "Acur√°cia": metrics["accuracy"],
            "Precis√£o": metrics["precision"],
            "Recall": metrics["recall"],
            "F1-score": metrics["f1"],
            "Falsos Positivos (FP)": int(fp),
            "Falsos Negativos (FN)": int(fn),
            "max_features": max_feats,
            "test_size": test_size
        }

        # Evita duplica√ß√£o (BOW vs TF-IDF)
        st.session_state.results_compare = [
            r for r in st.session_state.results_compare
            if r["Representa√ß√£o"] != rep
        ]
        st.session_state.results_compare.append(result)

    if len(st.session_state.results_compare) >= 2:
        st.subheader("üìä Compara√ß√£o entre BOW e TF-IDF")

        df_compare = pd.DataFrame(st.session_state.results_compare)
        df_compare = df_compare.set_index("Representa√ß√£o")

        st.dataframe(
            df_compare.style.format("{:.4f}")
                            .highlight_max(axis=0, color="green"),
            use_container_width=True
        )



# ----------------------- Integrante 3 -----------------------
if page == "3 - Explica√ß√µes com LIME":
    st.header("3 ‚Äî Explica√ß√µes com LIME (local)")
    st.markdown("A seguir vamos carregar um modelo treinado (TF-IDF por padr√£o) e mostrar explica√ß√µes locais com LIME para 3 exemplos: 2 corretos e 1 incorreto.")

    # try to load trained model
    rep_choice = st.selectbox("Carregar modelo treinado (representa√ß√£o)", ("TF-IDF", "BOW"))
    vec_path = MODEL_DIR / f"vectorizer_{rep_choice}.pkl"
    clf_path = MODEL_DIR / f"clf_logreg_{rep_choice}.pkl"

    if not vec_path.exists() or not clf_path.exists():
        st.warning("Modelos n√£o encontrados em ./models/. Treine um modelo na p√°gina 'Integrante 2' antes de usar LIME.")
    else:
        vec = joblib.load(vec_path)
        clf = joblib.load(clf_path)

        # wrap classifier for LIME (expects raw text -> predict_proba)
        class_names = list(le.classes_)
        explainer = LimeTextExplainer(class_names=class_names)

        s = preprocess_text(df['text'], remove_stopwords=False)
        X_train, X_test, y_train, y_test = train_test_split(s, df['label_enc'], test_size=0.2, stratify=df['label_enc'], random_state=42)
        X_test = X_test.reset_index(drop=True)
        y_test = y_test.reset_index(drop=True)

        # predict and find examples: two correct and one incorrect
        X_test_trans = vec.transform(X_test)
        y_pred = clf.predict(X_test_trans)
        correct_idx = np.where(y_pred == y_test)[0]
        wrong_idx = np.where(y_pred != y_test)[0]

        chosen = []
        if len(correct_idx) >= 2:
            chosen.extend(list(correct_idx[:2]))
        if len(wrong_idx) >= 1:
            chosen.append(int(wrong_idx[0]))

        st.write(f"Exemplos escolhidos (√≠ndices no conjunto de teste): {chosen}")

        for idx in chosen:
            st.markdown(f"---\n### Exemplo √≠ndice {idx}")
            text = X_test.iloc[idx]
            true = y_test.iloc[idx]
            pred = y_pred[idx]
            st.write(f"Texto: {text}")
            st.write(f"R√≥tulo verdadeiro: {le.inverse_transform([true])[0]} | Predito: {le.inverse_transform([pred])[0]}")

            # LIME explanation
            predict_proba = lambda texts: clf.predict_proba(vec.transform(texts))
            exp = explainer.explain_instance(text, predict_proba, num_features=10)
            st.subheader("Explica√ß√£o LIME (palavras e pesos)")
            # Show as table
            exp_map = exp.as_list()
            df_exp = pd.DataFrame(exp_map, columns=["feature", "weight"]) 
            st.table(df_exp)

            # plot and show
            fig = exp.as_pyplot_figure()
            st.pyplot(fig)

        # Aggregate LIME importances across a sample of instances for top 20
        st.subheader("Top 20 palavras (agrega√ß√£o LIME sobre 200 amostras)")
        sample_idx = np.random.choice(range(len(X_test)), size=min(200, len(X_test)), replace=False)
        agg = {}
        for i in sample_idx:
            text = X_test.iloc[i]
            num_feats = min(50, len(text.split()))
            tokens = text.split()
            doc_size = len(tokens)

            if doc_size < 2:
                st.warning("Mensagem muito curta para gerar explica√ß√£o com LIME.")
                continue

            num_feats = min(20, doc_size)
            from lime.lime_text import LimeTextExplainer
            explainer_lime = LimeTextExplainer(class_names=['ham', 'spam'])
            exp = explainer_lime.explain_instance(
                text,
                predict_proba,
                num_features=num_feats,
                num_samples=1000
            )
            for feat, w in exp.as_list():
                # feat might be like 'word'=1; ensure consistent token
                token = feat
                agg[token] = agg.get(token, 0) + abs(w)
        agg_series = pd.Series(agg).sort_values(ascending=False).head(20)
        fig, ax = plt.subplots(figsize=(8,6))
        agg_series[::-1].plot.barh(ax=ax)
        ax.set_title('Top 20 palavras ‚Äî LIME (soma dos pesos absolutos)')
        st.pyplot(fig)

# ----------------------- Integrante 4 -----------------------
if page == "4 - Explica√ß√µes com SHAP":
    st.header("4 ‚Äî Explica√ß√µes com SHAP (global e local)")
    st.markdown("Carregue o mesmo modelo treinado e vamos gerar gr√°ficos globais e locais com SHAP.\n**Aten√ß√£o:** SHAP pode usar bastante mem√≥ria para matrizes grandes. Recomendado usar modelo TF-IDF com max_features pequeno (ex: 5000).")

    rep_choice = st.selectbox("Carregar modelo treinado (representa√ß√£o)", ("TF-IDF", "BOW"), key="shap_rep")
    vec_path = MODEL_DIR / f"vectorizer_{rep_choice}.pkl"
    clf_path = MODEL_DIR / f"clf_logreg_{rep_choice}.pkl"

    if not vec_path.exists() or not clf_path.exists():
        st.warning("Modelos n√£o encontrados em ./models/. Treine um modelo na p√°gina 'Integrante 2' antes de usar SHAP.")
    else:
        vec = joblib.load(vec_path)
        clf = joblib.load(clf_path)

        s = preprocess_text(df['text'], remove_stopwords=False)
        X_train, X_test, y_train, y_test = train_test_split(s, df['label_enc'], test_size=0.2, stratify=df['label_enc'], random_state=42)
        X_test = X_test.reset_index(drop=True)
        y_test = y_test.reset_index(drop=True)

        # Transform to numeric
        X_train_mat = vec.transform(X_train)
        X_test_mat = vec.transform(X_test)

        st.subheader("SHAP ‚Äî Global summary plot (top features)")
        # For linear models, use LinearExplainer for efficiency
        with st.spinner("Calculando valores SHAP (pode demorar)..."):
            try:
                explainer = shap.LinearExplainer(clf, X_train_mat, feature_perturbation="interventional")
            except Exception as e:
                # fallback
                explainer = shap.Explainer(clf, X_train_mat)
            shap_values = explainer.shap_values(X_test_mat)

        # shap_values shape: (n_classes, n_samples, n_features) for multiclass or (n_samples, n_features)
        # For binary logistic regression sklearn returns shape (n_samples, n_features)
        # We'll compute mean absolute shap per feature
        if isinstance(shap_values, list):
            # multiclass -> take class 1
            sv = shap_values[1]
        else:
            sv = shap_values
        mean_abs = np.abs(sv).mean(axis=0)
        feature_names = np.array(vec.get_feature_names_out())
        top20_idx = np.argsort(mean_abs)[-20:][::-1]
        top20 = pd.Series(mean_abs[top20_idx], index=feature_names[top20_idx])

        fig, ax = plt.subplots(figsize=(8,6))
        top20[::-1].plot.barh(ax=ax)
        ax.set_title('Top 20 palavras ‚Äî SHAP (mean |SHAP value|)')
        st.pyplot(fig)

        st.markdown("\n**SHAP summary plot (pontos)**")
        # show summary plot
        try:
            fig2 = plt.figure()
            shap.summary_plot(sv, features=X_test_mat, feature_names=feature_names, show=False, max_display=20)
            st.pyplot(fig2)
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel gerar o summary_plot interativo: {e}")

        st.subheader("SHAP ‚Äî Explica√ß√£o local (waterfall) para um exemplo)")
        idx = st.number_input("√çndice do exemplo no conjunto de teste (0..)", min_value=0, max_value=max(0, len(X_test)-1), value=0)
        # Compute and plot waterfall
        try:
            shap_val_example = sv[idx]
            base_value = explainer.expected_value if hasattr(explainer, 'expected_value') else explainer.expected_value[1]
            fig3 = plt.figure(figsize=(6,4))
            shap.plots.waterfall(shap.Explanation(values=shap_val_example, base_values=base_value, data=X_test_mat[idx].toarray().ravel(), feature_names=feature_names), show=False)
            st.pyplot(fig3)
        except Exception as e:
            st.warning(f"Erro ao gerar waterfall: {e}")

        # Compare top 20 from LIME and SHAP if LIME agg file exists in memory (we'll compute LIME agg on the fly but warn about time)
        if st.checkbox("Gerar agrega√ß√£o LIME (para compara√ß√£o com SHAP) ‚Äî pode demorar"):
            explainer_lime = LimeTextExplainer(class_names=list(le.classes_))
            sample_idx = np.random.choice(range(len(X_test)), size=min(200, len(X_test)), replace=False)
            agg = {}
            predict_proba = lambda texts: clf.predict_proba(vec.transform(texts))
            with st.spinner("Computando LIME em 200 amostras..."):
                for i in sample_idx:
                    text = X_test.iloc[i]
                    num_feats = min(10, len(text.split()))
                    exp = explainer_lime.explain_instance(text, predict_proba, num_features=num_feats)
                    for feat, w in exp.as_list():
                        agg[feat] = agg.get(feat, 0) + abs(w)
            agg_series = pd.Series(agg).sort_values(ascending=False).head(20)
            fig, ax = plt.subplots(figsize=(8,6))
            agg_series[::-1].plot.barh(ax=ax)
            ax.set_title('Top 20 palavras ‚Äî LIME (soma dos pesos absolutos)')
            st.pyplot(fig)

# ----------------------- Integrante 5 -----------------------
if page == "5 - S√≠ntese e An√°lise Cr√≠tica do Projeto":
    st.header("5 ‚Äî S√≠ntese e An√°lise Cr√≠tica do Projeto")

    st.markdown("""
    ## üéØ Objetivo Geral
    Este projeto integrou pr√©-processamento textual, modelos supervisionados lineares
    e t√©cnicas de interpretabilidade (LIME e SHAP) aplicados ao dataset *SMS Spam Collection*.

    ## üß† Principais Contribui√ß√µes
    - Constru√ß√£o de um **pipeline completo** de classifica√ß√£o bin√°ria.
    - Compara√ß√£o entre duas formas de vetoriza√ß√£o:
      - **Bag-of-Words**
      - **TF-IDF**
    - Avalia√ß√£o de desempenho usando m√©tricas fundamentais:
      - Accuracy
      - Precision
      - Recall
      - F1-score
    - Interpreta√ß√£o das previs√µes com:
      - **LIME**: interpretabilidade local
      - **SHAP**: interpretabilidade global e local

    ## üìà An√°lises Cr√≠ticas
    ### 1. Sobre o dataset
    - Cont√©m textos curtos e altamente redundantes.
    - Varia√ß√£o limitada de vocabul√°rio reduz impacto de modelos complexos.
    - Classe "spam" √© minorit√°ria, exigindo cuidado com m√©tricas.

    ### 2. Sobre os modelos
    - Modelos lineares (LogisticRegression, LinearSVC) s√£o adequados.
    - TF-IDF apresentou geralmente desempenho superior ao BOW.
    - Modelos mais complexos (transformers) n√£o seriam necess√°rios para este trabalho.

    ### 3. Sobre LIME
    - Explica√ß√µes intuitivas, √∫teis para textos curtos.
    - Limita√ß√µes:
      - Depend√™ncia da perturba√ß√£o aleat√≥ria.
      - Instabilidade quando o texto tem poucas palavras.
      - Tempo de execu√ß√£o maior em an√°lises globais.

    ### 4. Sobre SHAP
    - Oferece vis√£o global mais est√°vel.
    - Requer mais mem√≥ria e apresenta maior custo computacional.
    - Excelente para discutir transpar√™ncia e √©tica em IA.

    ### 5. Compara√ß√£o LIME vs SHAP
    | Crit√©rio | LIME | SHAP |
    |---------|------|-------|
    | Foco | Local | Global + Local |
    | Estabilidade | M√©dia | Alta |
    | Interpreta√ß√£o | Muito intuitiva | Pode ser mais complexa |
    | Custo computacional | M√©dio | Alto |
    | Melhor uso | Explicar previs√£o individual | Analisar import√¢ncia geral |

    ## üìù Conclus√£o Geral
    O projeto demonstrou que:
    - Modelos lineares continuam extremamente eficientes para problemas de spam.
    - Escolhas de vetoriza√ß√£o influenciam mais do que o tipo de modelo.
    - Ferramentas de interpretabilidade s√£o essenciais para justificar decis√µes de IA.
    - A uni√£o entre desempenho e interpretabilidade deve sempre ser incentivada
      em ambientes educacionais e profissionais.

    ## üìå Sugest√µes de Trabalhos Futuros
    - Adicionar embeddings como Word2Vec, GloVe ou FastText.
    - Testar Naive Bayes otimizado para texto.
    - Comparar com modelos baseados em Transformers.
    - Criar gr√°ficos interativos usando Plotly ou Streamlit-AgGrid.
    - Aplicar o pipeline a outros tipos de texto, como fake news ou sentiment analysis.
    """)

    st.success("P√°gina 5 carregada com sucesso!")



